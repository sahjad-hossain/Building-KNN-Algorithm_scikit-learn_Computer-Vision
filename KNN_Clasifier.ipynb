{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Title: Reverse image search by Implementing the KNN classification with scikit-learn\n",
    "Key Notes: \n",
    "1.\tFeatures using the Euclidean distance with scikit-learn.\n",
    "2.\tHOG implementation of scikit-image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use `pip install` to add the following packages to your system\n",
    "- seaborn\n",
    "- sklearn == 0.22.1\n",
    "- pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter \n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from skimage.feature import hog\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from IPython.display import display, clear_output\n",
    "from PIL import Image, ImageOps\n",
    "from glob import glob\n",
    "import warnings\n",
    "from random import shuffle\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sn.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read a list of images from hdd\n",
    "files = glob('resources/images/**/*.jpg')\n",
    "shuffle(files)\n",
    "\n",
    "# convert all images to an rgb image\n",
    "images = [Image.open(x).convert('RGB') for x in files]\n",
    "\n",
    "# extract the class of each image based on the folder where the image is located\n",
    "labels = [f.split(os.path.sep)[-2] for f in files]\n",
    "\n",
    "# instanciate a label encoder to convert text labels into numerical labels\n",
    "le = LabelEncoder()\n",
    "y_true = le.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using KNN\n",
    "\n",
    "For this task you have to implement the KNN classification based on features using the Euclidean distance. What kind of features you use is up to you but a good starting point is the implementation of the [Histogram of Ordientated Gradients](https://scikit-image.org/docs/dev/api/skimage.feature.html?highlight=hog#skimage.feature.hog). You can also combine multiple features which you use for your final classification. A list of additional features can be found [here](https://scikit-image.org/docs/dev/api/skimage.feature.html).\n",
    "\n",
    "For example, you use the HOG implementation of scikit-image with 9 orientations and 32 pixels per cell in an image with 128 x 128px, you receive a feature vector with the length of 324. Another feature will be based on the mean color in a consistent grid. You seperate your source image in a 4 x 4 grid and calculate the mean color of each cell, this results in a feature vector with the dimension 4 x 4 x 3 which you need to flatten to the length of 48. For your final feature vector you just need concatenate both vectors to a final feature vector of size 372. \n",
    "\n",
    "\n",
    "### Confusion Matrix\n",
    "Based on the results for your KNN classification you have to create the [confusion matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html). Once this is done, you have to calculate the **Accuracy**, **Precision** and **Recall** by using the confusion matrix. \n",
    "\n",
    "![](resources/confusion_matrix.png)\n",
    "\n",
    "**Hints**\n",
    "\n",
    "- For HOG you have to use the same image size for all calculations otherwise you get different feature vectors whith different length\n",
    "- If you use color as feature, try to normalize these values\n",
    "- np.concatenate allows you to merge your feature to the final feature vector\n",
    "- np.argsort return the indices of a sorted array \n",
    "- you can calculate the precision, recall a.s.o from the confusion matrix like below\n",
    "\n",
    "<table align=\"left\"><tr><td>\n",
    "<img src=\"resources/hint_cm.png\" align=\"left\" width=300 />\n",
    "    </td></tr>\n",
    "    <tr><td>\n",
    "    <small>Source: https://stackoverflow.com/questions/31324218/scikit-learn-how-to-obtain-true-positive-true-negative-false-positive-and-fal</small>\n",
    "        </td></tr></table>\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_plot = None\n",
    "def run_similarity(features, event=None):\n",
    "    \"\"\" \n",
    "    Creates an image grid for the similarity search example\n",
    "    \"\"\"\n",
    "    \n",
    "    clear_output()\n",
    "    idx = 0\n",
    "    \n",
    "    if event is not None and hasattr(event.inaxes, 'name'):\n",
    "        idx = int(event.inaxes.name)\n",
    "    \n",
    "    query_feature = features[idx]\n",
    "    k = len(features)\n",
    "    indices = knn(query_feature, features, k)\n",
    "    \n",
    "    return plot_image_grid(images[idx], indices, features)\n",
    "\n",
    "def plot_image_grid(query, indices, features): \n",
    "    global similarity_plot\n",
    "    \n",
    "    if similarity_plot is None:\n",
    "        similarity_plot = plt.subplots(1,2, figsize=(10,6))\n",
    "        similarity_plot[0].canvas.mpl_connect('button_press_event', lambda x: run_similarity(features, x))\n",
    "        \n",
    "    similarity_plot[0].patch.set_visible(False)\n",
    "    \n",
    "    similarity_plot[1][0].set_title(\"Query\")\n",
    "    similarity_plot[1][0].axis('off')\n",
    "    similarity_plot[1][0].imshow(query)\n",
    "    similarity_plot[1][0].grid(False)\n",
    "    \n",
    "    grid = ImageGrid(similarity_plot[0], 122, nrows_ncols=(10,10), axes_pad=0)\n",
    "    similarity_plot[1][1].set_title(\"Results\")\n",
    "    similarity_plot[1][1].axis('off')\n",
    "    \n",
    "    for ax, idx in zip(grid, indices):\n",
    "        ax.axis('off')\n",
    "        ax.name = idx\n",
    "        ax.imshow(ImageOps.fit(images[idx], (64,64), Image.ANTIALIAS))\n",
    "        \n",
    "    plt.tight_layout()    \n",
    "    \n",
    "def plot_confusion_matrix(cm, label_names, ax): \n",
    "    \"\"\" \n",
    "    Function to plot a confusion matrix\n",
    "    \n",
    "    Args:\n",
    "        cm (np.ndarray): Confusion matrix to visualize\n",
    "        label_names (list of strings): label names used as x and y axis label\n",
    "    \"\"\"    \n",
    "    df_cm = pd.DataFrame(cm, label_names, label_names)\n",
    "    sn.set(font_scale=1) # for label size    \n",
    "    sn.heatmap(df_cm, annot=True, cmap='Blues', cbar=False, ax=ax) # font size\n",
    "    \n",
    "    accuracy, precision, recall = get_metrics(cm)\n",
    "    stats = f\"\\nAccuracy {accuracy:.3f}\\nPrecision {precision:.3f}\\nRecall {recall:.3f}\\n\"\n",
    "    ax.set_ylabel('True Label')\n",
    "    ax.set_xlabel('Predicted Label \\n' + stats)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(images[10]), display(images[10].resize((4,4), Image.NEAREST).resize((128,128), Image.NEAREST))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = np.array([10,5,0,20,3])\n",
    "args = np.argsort(distances)\n",
    "\n",
    "args, distances[args]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_color_feature(sample):\n",
    "    return np.array(sample.resize((4,4), Image.NEAREST)).flatten() / 255.0\n",
    "\n",
    "def calculate_hog(sample):\n",
    "    sample = sample.resize((128,128))\n",
    "    return hog(sample, pixels_per_cell=(16, 16))\n",
    "\n",
    "def get_metrics(cm):\n",
    "    \"\"\"\n",
    "    Calculates the Accuracy, Precision and Recall based on a confusion matrix\n",
    "    \n",
    "    Args:\n",
    "        cm (np.ndarray): Confusion Matrix        \n",
    "        \n",
    "    Returns:\n",
    "        tuple(float, float, float): Returns a tuple containing the accuracy, precission and recall for a confusion matrix    \n",
    "    \"\"\"\n",
    "    recall = np.diag(cm) / np.sum(cm, axis = 1)\n",
    "    precision = np.diag(cm) / np.sum(cm, axis = 0)\n",
    "    accuracy = np.diag(cm) / np.sum(cm)\n",
    "        \n",
    "    return accuracy.sum(), precision.mean(), recall.mean()\n",
    "\n",
    "def get_features(sample):\n",
    "    \"\"\"\n",
    "    Calculates a feature vector for an image\n",
    "    \n",
    "    Args:\n",
    "        sample (Pil.Image): Image for which a feature vector is to be calculated \n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: calculated feature vecotr witn (N,) dimension\n",
    "    \"\"\"\n",
    "    color = calculate_color_feature(sample)\n",
    "    hog = calculate_hog(sample)\n",
    "    \n",
    "    return np.concatenate([hog, color])\n",
    "\n",
    "def knn(query, features, k):    \n",
    "    \"\"\"\n",
    "    Applies a K-Nearest-Neighboor search for a query feature\n",
    "    \n",
    "    Args:\n",
    "        query (np.ndarray): Feature vector for searching the K nearest neighbour\n",
    "        features (List of np.ndarray): Set of feature vectors to find the nearest neighbour of an query feature vector\n",
    "        k (int): number of nearest nighbour\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: List of indices of k nearest neighboor\n",
    "    \"\"\"    \n",
    "    dist = []\n",
    "    for feature in features:\n",
    "        dist += [np.sqrt(np.square(query - feature).sum())]\n",
    "        \n",
    "    return np.argsort(dist)[:k]  \n",
    "\n",
    "\n",
    "def classification(features, k):\n",
    "    \"\"\"\n",
    "    Applies a K-Nearest-Neighboor classification\n",
    "    \n",
    "    Args: \n",
    "        features (List of np.ndarray): Set of features to find the nearest neighbour of an query feature\n",
    "        k (int): number of nearest nighbour\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: List of predicted labels\n",
    "    \"\"\"\n",
    "    y_pred = np.zeros_like(y_true)\n",
    "    for idx, (label, feature) in enumerate(zip(y_true,features)):\n",
    "        indices = knn(feature, features, k+1)\n",
    "        indices = [y_true[x] for x in indices][1:]        \n",
    "        indices, counts = np.unique(d,return_counts=True)\n",
    "        y_pred[idx] = indices[np.argmax(counts)]\n",
    "    \n",
    "    return y_pred  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.array([[3,1,2,1],\n",
    "              [1,6,2,3],\n",
    "              [2,2,4,2],\n",
    "              [7,1,2,5]])\n",
    "\n",
    "print(np.diag(m))\n",
    "print(np.sum(m, axis=1))\n",
    "print(np.sum(m, axis=0))\n",
    "\n",
    "a, p, r = get_metrics(m)\n",
    "print(f\"Accuracy: {a:.3f}\\nPrecision: {p:.3f}\\nRecall: {r:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = knn(features[5], features, 3+1)[1:]\n",
    "print(indices)\n",
    "d = [y_true[x] for x in indices]\n",
    "print(d)\n",
    "indices, counts = np.unique(d,return_counts=True)\n",
    "print(indices, counts, np.argmax(counts))\n",
    "indices[np.argmax(counts)], indices, counts, d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [get_features(image) for image in images]\n",
    "\n",
    "y_pred = classification(features, 5)\n",
    "cm = confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just a check to compare the calculated results with the well implemented sklearn versions\n",
    "acc, precision, recall = get_metrics(cm)\n",
    "assert precision_score(y_true, y_pred, average=None).mean() == precision\n",
    "assert recall_score(y_true, y_pred, average=None).mean() == recall\n",
    "assert accuracy_score(y_true, y_pred).mean() == acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(6,6))\n",
    "ax = plot_confusion_matrix(cm, le.inverse_transform(np.unique(y_true)), ax)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity\n",
    "\n",
    "Your KNN implementation and the selected features can be used for a reverse image search. You only need to execute the run_similarity(). With a click on the image grid (right subplot) you can select your query image.\n",
    "\n",
    "![](resources/similarity.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_similarity(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array(images[10].resize((128,128)))\n",
    "feature, hog_img = hog(test, pixels_per_cell=(32, 32), visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_feature = np.array(images[10].resize((4,4), Image.NEAREST)).flatten() / 255.0\n",
    "\n",
    "np.concatenate([color_feature, feature]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature.min(), feature.max(), color_feature.min(), color_feature.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis('off')\n",
    "plt.imshow(test)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(hog_img)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = (np.random.rand(3,3) * 10).astype(np.uint)\n",
    "cm, get_metrics(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
